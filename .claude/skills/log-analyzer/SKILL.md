---
name: log-analyzer
description: Analyze Claude Code hook logs using Gemini CLI in headless mode. Use this skill when analyzing video generation logs, debugging sub-agent execution, tracking token usage, or investigating errors across video pipeline runs.
---

# Log Analyzer Skill

Analyze Claude Code sub-agent hook logs to understand execution flow, token usage, errors, and performance across video generation runs.

## Overview

This skill uses **Gemini CLI in headless mode** to analyze log files from the `hooks_logs` directory. Logs are generated by the `subagent-stop-hook` and contain full execution transcripts of each sub-agent.

## Log File Patterns

Log files follow this naming convention:
```
{timestamp}_{topic}_{Step}_{scene}.log
```

**Steps:**
- `Direction_root` - Video direction generation
- `Assets_root` - SVG asset generation
- `Design_{0-9}` - Design specification for each scene
- `Video_{0-9}` - React component generation for each scene

**Example files:**
```
2025-12-17_11-19-14_hypersonic-warfare-m9k3_Video_0.log
2025-12-16_17-21-25_hypersonic-warfare-m9k3_Direction_root.log
2025-12-16_12-24-26_hypersonic-missiles-warfare-k7m3_Design_1.log
```

## Usage Workflow

### Step 1: Extract Metadata First (CRITICAL)

Log files are **large** (100KB-600KB) and contain full file contents that agents read/wrote.
**NEVER** read raw log files directly - use the metadata extraction script:

```bash
# List available topics
python .claude/skills/log-analyzer/scripts/extract_log_metadata.py \
  --logs-dir "Outputs/hooks_logs" \
  --list-topics

# Extract metadata for a specific topic and step
python .claude/skills/log-analyzer/scripts/extract_log_metadata.py \
  --logs-dir "Outputs/hooks_logs" \
  --topic "hypersonic-warfare-m9k3" \
  --step "Design" \
  --output summary

# Get JSON output for detailed analysis
python .claude/skills/log-analyzer/scripts/extract_log_metadata.py \
  --logs-dir "Outputs/hooks_logs" \
  --topic "hypersonic-warfare-m9k3" \
  --output json > /tmp/log_analysis.json
```

### Step 2: Use Gemini CLI for Deep Analysis

After extracting metadata, use Gemini CLI in headless mode for intelligent analysis:

```bash
# Basic analysis with auto-approval
gemini --yolo "Analyze this log summary and identify issues: $(cat /tmp/log_analysis.json | head -1000)"

# Structured JSON output
gemini --output-format json --yolo "Analyze these log metrics..."

# With specific model
gemini --model gemini-2.0-flash-exp --yolo "..."
```

**Gemini CLI Options:**
- `--yolo` or `--approval-mode yolo` - Auto-approve all actions (headless mode)
- `--output-format json` - Return structured JSON response
- `--model <model>` - Specify model (default: gemini-2.0-flash-exp)
- Positional argument - Your prompt/query

### Step 3: Analysis Templates

**Token Usage Analysis:**
```bash
python .claude/skills/log-analyzer/scripts/extract_log_metadata.py \
  --logs-dir "Outputs/hooks_logs" \
  --topic "YOUR_TOPIC" \
  --output json | \
gemini --yolo "Analyze token usage patterns from this log data. Identify:
1. Which steps consume the most tokens
2. Cache hit rates
3. Recommendations to reduce token usage"
```

**Error Investigation:**
```bash
python .claude/skills/log-analyzer/scripts/extract_log_metadata.py \
  --logs-dir "Outputs/hooks_logs" \
  --topic "YOUR_TOPIC" \
  --output json | \
gemini --yolo "Find all errors and failures in this log data. For each error:
1. Which step and scene failed
2. The error message/type
3. Likely root cause
4. Suggested fix"
```

**Execution Flow Analysis:**
```bash
python .claude/skills/log-analyzer/scripts/extract_log_metadata.py \
  --logs-dir "Outputs/hooks_logs" \
  --topic "YOUR_TOPIC" \
  --step "Video" \
  --output json | \
gemini --yolo "Analyze the execution flow of these Video generation sub-agents:
1. Sequence and timing of each scene
2. Tool usage patterns
3. Any bottlenecks or repeated operations
4. Recommendations for efficiency"
```

## Log File Structure

Each log file is JSON with this structure:

```json
{
  "hook_name": "subagent-stop-hook",
  "timestamp": "2025-12-17T11:19:14.898622",
  "input": {
    "session_id": "f110974a-...",
    "agent_id": "a7c3d70",
    "agent_transcript_data": [
      {
        "type": "user",
        "message": { "role": "user", "content": "..." },
        "timestamp": "..."
      },
      {
        "type": "assistant",
        "message": {
          "model": "claude-sonnet-4-5-20250929",
          "content": [...],
          "usage": {
            "input_tokens": 3,
            "output_tokens": 161,
            "cache_creation_input_tokens": 8325,
            "cache_read_input_tokens": 0
          }
        },
        "timestamp": "..."
      }
    ]
  }
}
```

**Key fields to analyze:**
- `usage` - Token consumption per message
- `content` - Tool calls (`type: "tool_use"`) and results (`type: "tool_result"`)
- `is_error` - Whether tool result was an error
- Completion markers like "AGENT COMPLETED RUNNING" and "Status: success/failed"

## Output Metrics

The metadata extractor provides:

| Metric | Description |
|--------|-------------|
| `total_input_tokens` | Sum of input tokens across all messages |
| `total_output_tokens` | Sum of output tokens across all messages |
| `total_cache_creation_tokens` | Tokens used for prompt caching |
| `total_cache_read_tokens` | Tokens served from cache |
| `completion_status` | success, failed, or unknown |
| `duration_seconds` | Time from first to last message |
| `tool_calls` | List of all tool invocations |
| `errors` | List of errors with previews |
| `tool_call_summary` | Count of each tool type used |

## Example Analysis Session

```bash
# 1. Navigate to Outputs directory with logs
cd Outputs
git checkout origin/infographicshow/hypersonic-missile-v2

# 2. List available topics
python ../.claude/skills/log-analyzer/scripts/extract_log_metadata.py \
  --logs-dir hooks_logs --list-topics

# 3. Get summary for a specific topic's Designer step
python ../.claude/skills/log-analyzer/scripts/extract_log_metadata.py \
  --logs-dir hooks_logs \
  --topic "hypersonic-warfare-m9k3" \
  --step "Design" \
  --output summary

# 4. Deep dive with Gemini on the Designer logs
python ../.claude/skills/log-analyzer/scripts/extract_log_metadata.py \
  --logs-dir hooks_logs \
  --topic "hypersonic-warfare-m9k3" \
  --step "Design" \
  --output json | \
gemini --yolo --output-format text "
Given this log analysis JSON, provide a detailed report including:

## Summary
- Total scenes analyzed
- Overall success rate
- Total token usage

## Issues Found
- List each error with step, scene, and description
- Identify patterns in failures

## Token Efficiency
- Which scenes used the most tokens
- Cache hit ratio analysis
- Recommendations

## Execution Flow
- Timeline of scene generation
- Parallel vs sequential execution
- Any retries detected
"
```

## Troubleshooting

**Issue: Gemini CLI not found**
```bash
# Install via npm
npm install -g @anthropic-ai/gemini-cli
# Or check path
which gemini
```

**Issue: Log files not found**
```bash
# Check you're in the right Outputs branch
cd Outputs
git branch -v
git fetch --all
git checkout origin/YOUR_BRANCH
ls hooks_logs/
```

**Issue: Context too large**
- Use `--step` filter to analyze one step at a time
- Use `--output summary` instead of `json` for large datasets
- Pipe through `head -N` to limit JSON size
